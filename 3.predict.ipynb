{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 模型解码/预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import pickle\n",
    "import random\n",
    "from functools import reduce\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "import librosa\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from scipy.fftpack import dct\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "keras = tf.keras\n",
    "ctc_decode, get_value, load_model = (\n",
    "    keras.backend.ctc_decode,\n",
    "    keras.backend.get_value,\n",
    "    keras.models.load_model,\n",
    ")\n",
    "\n",
    "# 音频/语音标注文件路径\n",
    "DS_PATH = \"data/\"\n",
    "# 模型文件路径\n",
    "FILES_PATH = \"output/\"\n",
    "\n",
    "# 音频文件路径\n",
    "data_path = sorted([str(p) for p in pathlib.Path(DS_PATH).glob(\"*.wav\")])\n",
    "# 语音标注文件路径\n",
    "label_path = sorted([str(p) for p in pathlib.Path(DS_PATH).glob(\"*.trn\")])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. 加载模型与数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset_mfcc(\n",
    "    file_path,\n",
    "    sr=16000,\n",
    "    n_mfcc=13,\n",
    "    n_fft=512,\n",
    "    min_db=23,\n",
    "    emphasis=0.97,\n",
    "    hop_length=0.01,\n",
    "    win_length=0.025,\n",
    "    lifter=22,\n",
    "    is_emphasis=False,\n",
    "):\n",
    "    \"\"\"\n",
    "    加载并提取音频特征, 返回经过预处理的音频mfcc数组\n",
    "    :param file_path:    list 音频文件路径\n",
    "    :param sr:           int 音频采样率\n",
    "    :param n_mfcc:       int mfcc特征维度\n",
    "    :param n_fft:        int stft计算点数\n",
    "    :param min_db:       float 删除静音片段的最小分贝数\n",
    "    :param emphasis:     float 预加重系数\n",
    "    :param hop_length:   float 分帧间隔长度\n",
    "    :param win_length:   float 分窗长度\n",
    "    :param lifter:       int 对倒谱应用系数提升, 数值为正数\n",
    "    :param is_emphasis:  bool 是否进行预加重\n",
    "    :return:             np.ndarray 包含所有音频文件的mfcc特征二维数组 (frames, n_mfcc)\n",
    "    \"\"\"\n",
    "    ds = list()\n",
    "    for path in tqdm(file_path):\n",
    "        # 读取文件\n",
    "        y, sr = librosa.load(path=path, sr=sr)\n",
    "\n",
    "        # 去除音频中所有的空白静默部分\n",
    "        y_split = librosa.effects.split(y, top_db=min_db)\n",
    "        y_split = np.array(list(reduce(lambda x, y: np.concatenate((x, y)), [y[x[0] : x[1]] for x in y_split])))\n",
    "\n",
    "        # 预加重\n",
    "        if is_emphasis:\n",
    "            y_split = librosa.effects.preemphasis(y_split, coef=emphasis)\n",
    "\n",
    "        # 提取Mel频谱\n",
    "        y_mel = librosa.feature.melspectrogram(\n",
    "            y=y_split, sr=sr, n_fft=n_fft, hop_length=int(sr * hop_length), win_length=int(sr * win_length)\n",
    "        )\n",
    "\n",
    "        # 对分贝频谱应用DCT得到MFCC特征\n",
    "        y_db = librosa.power_to_db(y_mel)\n",
    "        y_mfcc = dct(y_db, axis=-2, type=2, norm=\"ortho\")[..., :n_mfcc, :]\n",
    "\n",
    "        # 对MFCC应用提升系数, 可以提高高频部分的分辨率\n",
    "        if lifter > 0:\n",
    "            n_lifter = np.sin(np.pi * np.arange(1, 1 + n_mfcc, dtype=y_mfcc.dtype) / lifter)\n",
    "            n_lifter = librosa.util.expand_to(n_lifter, ndim=y_db.ndim, axes=-2)\n",
    "            y_mfcc *= 1 + (lifter / 2) * n_lifter\n",
    "\n",
    "        # 保存数据 (转置是为了与后续的模型输入层维度匹配)\n",
    "        ds.append(y_mfcc.transpose())\n",
    "\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取音频模型均值, 标准差\n",
    "with open(FILES_PATH + \"dataset/data_mfcc.pkl\", \"rb\") as file:\n",
    "    _, mfcc_mean, mfcc_std = pickle.load(file)\n",
    "    del _\n",
    "\n",
    "# 读取词库\n",
    "with open(FILES_PATH + \"dataset/words_vec.pkl\", \"rb\") as file:\n",
    "    char2id, id2char = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入保存的模型\n",
    "bigru_model = load_model(FILES_PATH + 'models/conv/bigru-conv-x6.h5')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 构建CTC解码模型\n",
    "CTC编码后的模型需要解码后才能输出对应标签的概率值  \n",
    "使用tf.keras.backend.ctc_decode进行解码  \n",
    "\n",
    "y_pred\t        包含预测的张量或 softmax 的输出 (samples, time_steps, num_categories)  \n",
    "input_length\t包含预测结果中每个批次序列长度的张量 (samples, 1)  \n",
    "greedy\t        如果true, 则执行更快的最佳路径搜索  \n",
    "beam_width\t    如果greedy是false, 波束搜索解码器将与此宽度的波束一起使用  \n",
    "top_paths\t    如果greedy是false, 将返回多少条最可能的路径  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ctc_decode_model(pred_audio, dict_list, model):\n",
    "    \"\"\"\n",
    "    使用模型对音频解码预测其内容\n",
    "    :param pred_audio:  需要预测的音频特征\n",
    "    :param dict_list:   转换标签所使用的词库\n",
    "    :param model:       预测使用的模型\n",
    "    :return:            (str, list) 返回预测的文本及其标签序号\n",
    "    \"\"\"\n",
    "    # 使用模型预测结果 (expand_dims用于增加维度匹配模型输入)\n",
    "    pred = model.predict(np.expand_dims(pred_audio, axis=0))\n",
    "    # 音频帧数\n",
    "    input_length = np.array((pred_audio.shape[1],))\n",
    "\n",
    "    # 解码\n",
    "    decode_res = ctc_decode(pred, input_length, greedy=True, beam_width=100, top_paths=1)\n",
    "    # 获取预测的序列数组, 筛选有效值 (> -1)\n",
    "    pred_index = get_value(decode_res[0][0])\n",
    "    pred_index = [item for item in pred_index[0] if item > -1]\n",
    "\n",
    "    # 使用词库将预测标号转换为文本\n",
    "    pred_text = \"\"\n",
    "    for index in pred_index:\n",
    "        pred_text += dict_list[index]\n",
    "\n",
    "    # 返回预测的文本及其标号\n",
    "    return pred_text, pred_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mfcc特征维数\n",
    "MFCC_VALUE = 32\n",
    "# FFT计算点数\n",
    "FFT = 512\n",
    "# 窗长\n",
    "WINLEN = 0.032\n",
    "\n",
    "# 随机读取读取一条语音\n",
    "index = random.randint(0, len(data_path) - 1)\n",
    "sound_mfcc = load_dataset_mfcc(\n",
    "    [data_path[index]],\n",
    "    n_mfcc=MFCC_VALUE,\n",
    "    is_emphasis=True,\n",
    "    n_fft=FFT,\n",
    "    win_length=WINLEN,\n",
    ")[0]\n",
    "# 标准化\n",
    "sound_mfcc = (sound_mfcc - mfcc_mean) / mfcc_std\n",
    "\n",
    "# 读取语音对应文本\n",
    "with open(label_path[index], \"r\") as file:\n",
    "    sound_text = file.readline().strip()\n",
    "\n",
    "print(sound_text)\n",
    "sound_mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigru_text, bigru_textid = ctc_decode_model(sound_mfcc, id2char, bigru_model)\n",
    "\n",
    "print(\"原文:\", sound_text.replace(\" \", \"\"))\n",
    "print(\"识别:\", bigru_text)\n",
    "print(\"标号:\", bigru_textid)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "7ad05525b964f9a3219eb93b0946337e1e9a632ab3f307ade25b62443cfe7aec"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
