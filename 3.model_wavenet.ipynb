{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. CTC + WaveNet模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-21T13:34:34.203249Z",
     "iopub.status.busy": "2023-02-21T13:34:34.203034Z",
     "iopub.status.idle": "2023-02-21T13:34:36.475468Z",
     "shell.execute_reply": "2023-02-21T13:34:36.474761Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import pickle\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.layers import BatchNormalization, Activation, Multiply, Add\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.backend import ctc_batch_cost\n",
    "from tensorflow.keras.layers import Input, Conv1D, Lambda\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 设置显存大小\n",
    "gpus = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "memory_size = tf.config.experimental.VirtualDeviceConfiguration(memory_limit=8704)\n",
    "tf.config.experimental.set_virtual_device_configuration(gpus[0], [memory_size])\n",
    "\n",
    "plt.rcParams[\"font.sans-serif\"] = [\"Microsoft YaHei\"]\n",
    "plt.rcParams[\"axes.unicode_minus\"] = False\n",
    "\n",
    "# 音频/语音标注文件路径\n",
    "DS_PATH = 'data/'\n",
    "# 模型文件路径\n",
    "MODELS_PATH = 'model/'\n",
    "# mfcc特征维数\n",
    "MFCC_VALUE = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. 读取数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-21T13:34:36.478806Z",
     "iopub.status.busy": "2023-02-21T13:34:36.478231Z",
     "iopub.status.idle": "2023-02-21T13:34:36.691223Z",
     "shell.execute_reply": "2023-02-21T13:34:36.690422Z"
    }
   },
   "outputs": [],
   "source": [
    "# 读取音频特征\n",
    "with open(MODELS_PATH + 'data_mfcc.pkl', 'rb') as file:\n",
    "    train_ds, mfcc_mean, mfcc_std = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-21T13:34:36.694411Z",
     "iopub.status.busy": "2023-02-21T13:34:36.693955Z",
     "iopub.status.idle": "2023-02-21T13:34:37.000866Z",
     "shell.execute_reply": "2023-02-21T13:34:37.000153Z"
    }
   },
   "outputs": [],
   "source": [
    "# 读取词库\n",
    "with open(MODELS_PATH + 'words_vec.pkl', 'rb') as file:\n",
    "    char2id, id2char = pickle.load(file)\n",
    "\n",
    "# 读取标签内容\n",
    "label_path = sorted([str(p) for p in pathlib.Path(DS_PATH).glob('*.trn')])\n",
    "train_label = list()\n",
    "for path in tqdm(label_path):\n",
    "    with open(path, 'r', encoding='utf-8') as file:\n",
    "        # 读取第一行的字标注\n",
    "        train_label.append(file.readline().strip().split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 构建CTC模型的input / output\n",
    "考虑到较大的数据量，可以定义一个generator批量为后续的训练模型输入数据\n",
    "**输入的数据需要按照 tf.keras.backend.ctc_batch_cost 的参数进行构造**\n",
    "\n",
    "y_true：         包含真值标签的张量 (samples, max_string_length)\n",
    "y_pred:          包含预测的张量或 softmax 的输出 (samples, time_steps, num_categories)\n",
    "input_length:    包含预测结果中每个批次序列长度的张量 (samples, 1)\n",
    "label_length:    包含真实标签中每个批次序列长度的张量 (samples, 1)\n",
    "\n",
    "**CTC模型数据构造函数已经包含了数据长度对齐的处理过程**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-21T13:34:37.003675Z",
     "iopub.status.busy": "2023-02-21T13:34:37.003354Z",
     "iopub.status.idle": "2023-02-21T13:34:37.012697Z",
     "shell.execute_reply": "2023-02-21T13:34:37.012023Z"
    }
   },
   "outputs": [],
   "source": [
    "def ctc_loss(args):\n",
    "    \"\"\"\n",
    "    构建CTC模型损失函数\n",
    "    :param args: 输入ctc_batch_cost的参数\n",
    "    :return:     (sample, 1) 每个批次内数据包含的CTC损失\n",
    "    \"\"\"\n",
    "    y_true, y_pred, input_length, label_length = args\n",
    "    return ctc_batch_cost(y_true, y_pred, input_length, label_length)\n",
    "\n",
    "\n",
    "def ctc_batch_generator(data, labels, dict_list, n_mfcc, max_length, batch_size):\n",
    "    \"\"\"\n",
    "    构建模型输入使用的CTC模型格式数据，包含长度对齐操作\n",
    "    :param dict_list:\n",
    "    :param data:        音频MFCC特征\n",
    "    :param labels:      语音标注标签(已转换为数字)\n",
    "    :param n_mfcc:      音频MFCC特征维数\n",
    "    :param max_length:  标签最大填充长度\n",
    "    :param batch_size:  每批次送入模型训练的数据数量\n",
    "    :return:            (dict, dict) 包含符合CTC模型格式的input/output数据\n",
    "    \"\"\"\n",
    "    # 初始批次数据量为0\n",
    "    cur_batch = 0\n",
    "    # 生成器\n",
    "    while True:\n",
    "        # 当前批次的数据量\n",
    "        cur_batch += batch_size\n",
    "        \"\"\"\n",
    "        这里使用 offset >= len(data) 判断条件是为了在offset索引超出长度时自动重置该值\n",
    "        防止后续的list操作溢出 (X_data切片取不到batch_size长度的数值)\n",
    "        同时重置offset值为最初的batch_size作为索引，并重新打乱数据\n",
    "        这样可以在之前所有批次数据取完后，重新给模型提供不一样的数据集(从头开始批次生成)\n",
    "        \"\"\"\n",
    "        # 在加载每批次的数据前打乱排序\n",
    "        if cur_batch == batch_size or cur_batch >= len(data):\n",
    "            shuffle_index = np.arange(len(data))\n",
    "            np.random.shuffle(shuffle_index)\n",
    "            # 保证数据与标签一一对应，需要使用同一套已经打乱顺序的标签\n",
    "            data = [data[x] for x in shuffle_index]\n",
    "            labels = [labels[x] for x in shuffle_index]\n",
    "            # 重置cur_batch索引值\n",
    "            cur_batch = batch_size\n",
    "\n",
    "        # 从数据集中获取一个批次的数据，个数为batch_size\n",
    "        X_data = data[cur_batch - batch_size:cur_batch]\n",
    "        y_data = labels[cur_batch - batch_size:cur_batch]\n",
    "\n",
    "        # 获取音频最大帧数作为统一长度 (保证所有数据的完整性)\n",
    "        max_frame = np.max([x.shape[0] for x in X_data])\n",
    "\n",
    "        # 以下过程是先按最大长度创建空间, 然后将没有对齐的数据直接放入空间中, 达到整体对齐的目的（填充法）\n",
    "        X_batch = np.zeros([batch_size, max_frame, n_mfcc])  # 输入的特征长度，填充为最大\n",
    "        y_batch = np.ones([batch_size, max_length]) * len(dict_list)  # 输入的标签长度填充为总词数\n",
    "        X_length = np.zeros([batch_size, 1], dtype=np.int16)  # 输入的数据量=批次数量\n",
    "        y_length = np.zeros([batch_size, 1], dtype=np.int16)  # 输入的特征量=批次数量\n",
    "\n",
    "        # 根据批次数据实时更新CTC输入\n",
    "        for i in range(batch_size):\n",
    "            X_length[i, 0] = X_data[i].shape[0]\n",
    "            X_batch[i, :X_length[i, 0], :] = X_data[i]\n",
    "\n",
    "            y_length[i, 0] = len(y_data[i])\n",
    "            y_batch[i, :y_length[i, 0]] = [dict_list[x] for x in y_data[i]]\n",
    "\n",
    "        # 保存构建的数据结构\n",
    "        ctc_inputs = {'X': X_batch, 'y': y_batch, 'X_length': X_length, 'y_length': y_length}\n",
    "        ctc_output = {'ctc': np.zeros([batch_size])}\n",
    "\n",
    "        # generator 迭代数据\n",
    "        yield ctc_inputs, ctc_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 构建WaveNet模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-21T13:34:37.015491Z",
     "iopub.status.busy": "2023-02-21T13:34:37.015083Z",
     "iopub.status.idle": "2023-02-21T13:34:37.025340Z",
     "shell.execute_reply": "2023-02-21T13:34:37.024687Z"
    }
   },
   "outputs": [],
   "source": [
    "def model_wavenet(words_size, n_mfcc, filter_range,\n",
    "                  n_filters=128, n_blocks=3, kernel_size=7):\n",
    "    \"\"\"\n",
    "    按照指定参数构建WaveNet模型\n",
    "    :param words_size:     词库大小\n",
    "    :param n_mfcc:         音频MFCC特征维数\n",
    "    :param filter_range:   list 卷积核扩大间隔范围\n",
    "    :param n_filters:      卷积核尺寸\n",
    "    :param n_blocks:       扩大层数\n",
    "    :param kernel_size:    扩大层(1-dim)卷积核尺寸\n",
    "    :return:               (wavenet, ctc_model) 返回构建的WaveNet模型和CTC Loss模型\n",
    "    \"\"\"\n",
    "    # 一维卷积层\n",
    "    def conv1d(inputs, filters, kernel_size, diltion_rate):\n",
    "        return Conv1D(filters=filters, kernel_size=kernel_size, strides=1,\n",
    "                      padding='causal', activation=None, dilation_rate=diltion_rate)(inputs)\n",
    "\n",
    "    # 标准化函数\n",
    "    def batchnorm(inputs):\n",
    "        return BatchNormalization()(inputs)\n",
    "\n",
    "    # 激活层函数\n",
    "    def activation(inputs, activation):\n",
    "        return Activation(activation)(inputs)\n",
    "\n",
    "    # 扩大卷积网络\n",
    "    def res_block(inputs, filters, kernel_size, dilation_rate):\n",
    "        res_1 = activation(batchnorm(conv1d(inputs, filters, kernel_size, dilation_rate)), 'tanh')\n",
    "        res_2 = activation(batchnorm(conv1d(inputs, filters, kernel_size, dilation_rate)), 'sigmoid')\n",
    "        res_add = Multiply()([res_1, res_2])\n",
    "\n",
    "        res_active_1 = activation(batchnorm(conv1d(res_add, filters, 1, 1)), 'tanh')\n",
    "        res_active_2 = activation(batchnorm(conv1d(res_add, filters, 1, 1)), 'tanh')\n",
    "\n",
    "        return Add()([res_active_1, inputs]), res_active_2\n",
    "\n",
    "    # 定义模型输入数据格式 (输入格式与ctc_batch_generator的返回值一致)\n",
    "    input_data = Input(shape=(None, n_mfcc), dtype=np.float32, name='X')\n",
    "\n",
    "    # 定义WaveNet模型结构 #\n",
    "    wav_1 = activation(batchnorm(conv1d(input_data, n_filters, 1, 1)), 'tanh')\n",
    "    shortcut = []\n",
    "    for index in range(n_blocks):\n",
    "        for r in filter_range:\n",
    "            wav_1, s = res_block(wav_1, n_filters, kernel_size, r)\n",
    "            shortcut.append(s)\n",
    "\n",
    "    wav_2 = activation(Add()(shortcut), 'relu')\n",
    "    wav_2 = activation(batchnorm(conv1d(wav_2, n_filters, 1, 1)), 'relu')\n",
    "    # softmax损失函数输出结果\n",
    "    conv_output = activation(batchnorm(conv1d(wav_2, words_size + 1, 1, 1)), 'softmax')\n",
    "    # 模型输出\n",
    "    wavenet_model = Model(inputs=input_data, outputs=conv_output)\n",
    "\n",
    "    # 定义CTC模型结构 #\n",
    "    # 定义CTC模型输入格式 (y_true, dense_output, input_length, label_length)\n",
    "    y_true = Input(shape=(None,), dtype=np.float32, name='y')\n",
    "    input_length = Input(shape=(1,), dtype=np.int16, name='X_length')\n",
    "    label_length = Input(shape=(1,), dtype=np.int16, name='y_length')\n",
    "    # 定义模型输出格式\n",
    "    ctc_loss_out = Lambda(ctc_loss, output_shape=(1,), name='ctc')([y_true, conv_output, input_length, label_length])\n",
    "    # 保存CTC模型结构\n",
    "    ctc_model = Model(inputs=[input_data, y_true, input_length, label_length],\n",
    "                      outputs=ctc_loss_out)\n",
    "    # 定义模型优化器, 编译模型\n",
    "    opt_sgd = SGD(learning_rate=0.02, momentum=0.9, nesterov=True, clipnorm=5)\n",
    "    ctc_model.compile(loss={'ctc': lambda ctc_true, ctc_pred: ctc_pred}, optimizer=opt_sgd)\n",
    "    # 输出模型信息\n",
    "    ctc_model.summary()\n",
    "\n",
    "    return wavenet_model, ctc_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 分割数据集 / 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-21T13:34:37.027740Z",
     "iopub.status.busy": "2023-02-21T13:34:37.027323Z",
     "iopub.status.idle": "2023-02-21T13:34:37.037049Z",
     "shell.execute_reply": "2023-02-21T13:34:37.036392Z"
    }
   },
   "outputs": [],
   "source": [
    "# 标签固定长度\n",
    "labels_length = 50\n",
    "# 每批次数据集大小\n",
    "batch_size = 50\n",
    "# 扩大范围\n",
    "filter_range = [1, 2, 4, 8, 16]\n",
    "# 训练次数\n",
    "epochs = 1000\n",
    "\n",
    "# 划分训练集/测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_ds, train_label,\n",
    "                                                    test_size=0.3, random_state=100)\n",
    "\n",
    "# CTC模型数据generator\n",
    "train_batch = ctc_batch_generator(X_train, y_train, char2id, MFCC_VALUE,\n",
    "                                  batch_size=batch_size, max_length=labels_length)\n",
    "test_batch = ctc_batch_generator(X_test, y_test, char2id, MFCC_VALUE,\n",
    "                                 batch_size=batch_size, max_length=labels_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-21T13:34:37.039346Z",
     "iopub.status.busy": "2023-02-21T13:34:37.038939Z",
     "iopub.status.idle": "2023-02-21T13:34:40.203535Z",
     "shell.execute_reply": "2023-02-21T13:34:40.202920Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "wavenet_model, ctc_model = model_wavenet(len(char2id), MFCC_VALUE, filter_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-21T13:34:40.207256Z",
     "iopub.status.busy": "2023-02-21T13:34:40.206807Z",
     "iopub.status.idle": "2023-02-25T01:50:52.973868Z",
     "shell.execute_reply": "2023-02-25T01:50:52.973175Z"
    }
   },
   "outputs": [],
   "source": [
    "# 训练模型\n",
    "history = ctc_model.fit(\n",
    "    train_batch,\n",
    "    epochs=epochs,\n",
    "    validation_data=test_batch,\n",
    "    steps_per_epoch=len(X_train) // batch_size,\n",
    "    validation_steps=len(X_test) // batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-25T01:50:52.977248Z",
     "iopub.status.busy": "2023-02-25T01:50:52.976798Z",
     "iopub.status.idle": "2023-02-25T01:50:53.301440Z",
     "shell.execute_reply": "2023-02-25T01:50:53.300768Z"
    }
   },
   "outputs": [],
   "source": [
    "# 保存模型\n",
    "wavenet_model.save(MODELS_PATH + 'wavenet.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "7ad05525b964f9a3219eb93b0946337e1e9a632ab3f307ade25b62443cfe7aec"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
