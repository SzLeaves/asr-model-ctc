{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 模型解码/预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import pickle\n",
    "import random\n",
    "from functools import reduce\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "import librosa\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from scipy.fftpack import dct\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "keras = tf.keras\n",
    "ctc_decode, get_value, load_model = (\n",
    "    keras.backend.ctc_decode,\n",
    "    keras.backend.get_value,\n",
    "    keras.models.load_model,\n",
    ")\n",
    "\n",
    "# 音频/语音标注文件路径\n",
    "DS_PATH = \"data/\"\n",
    "# 模型文件路径\n",
    "FILES_PATH = \"output/\"\n",
    "\n",
    "# 音频文件路径\n",
    "data_path = sorted([str(p) for p in pathlib.Path(DS_PATH).glob(\"*.wav\")])\n",
    "# 语音标注文件路径\n",
    "label_path = sorted([str(p) for p in pathlib.Path(DS_PATH).glob(\"*.trn\")])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. 加载模型与数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset_mfcc(\n",
    "    file_path,\n",
    "    sr=16000,\n",
    "    n_mfcc=13,\n",
    "    n_fft=512,\n",
    "    min_db=23,\n",
    "    emphasis=0.97,\n",
    "    hop_length=0.01,\n",
    "    win_length=0.025,\n",
    "    lifter=22,\n",
    "    is_emphasis=False,\n",
    "):\n",
    "    \"\"\"\n",
    "    加载并提取音频特征, 返回经过预处理的音频mfcc数组\n",
    "    :param file_path:    list 音频文件路径\n",
    "    :param sr:           int 音频采样率\n",
    "    :param n_mfcc:       int mfcc特征维度\n",
    "    :param n_fft:        int stft计算点数\n",
    "    :param min_db:       float 删除静音片段的最小分贝数\n",
    "    :param emphasis:     float 预加重系数\n",
    "    :param hop_length:   float 分帧间隔长度\n",
    "    :param win_length:   float 分窗长度\n",
    "    :param lifter:       int 对倒谱应用系数提升, 数值为正数\n",
    "    :param is_emphasis:  bool 是否进行预加重\n",
    "    :return:             np.ndarray 包含所有音频文件的mfcc特征二维数组 (frames, n_mfcc)\n",
    "    \"\"\"\n",
    "    ds = list()\n",
    "    for path in tqdm(file_path):\n",
    "        # 读取文件\n",
    "        y, sr = librosa.load(path=path, sr=sr)\n",
    "\n",
    "        # 去除音频中所有的空白静默部分\n",
    "        y_split = librosa.effects.split(y, top_db=min_db)\n",
    "        y_split = np.array(list(reduce(lambda x, y: np.concatenate((x, y)), [y[x[0] : x[1]] for x in y_split])))\n",
    "\n",
    "        # 预加重\n",
    "        if is_emphasis:\n",
    "            y_split = librosa.effects.preemphasis(y_split, coef=emphasis)\n",
    "\n",
    "        # 提取Mel频谱\n",
    "        y_mel = librosa.feature.melspectrogram(\n",
    "            y=y_split, sr=sr, n_fft=n_fft, hop_length=int(sr * hop_length), win_length=int(sr * win_length)\n",
    "        )\n",
    "\n",
    "        # 对分贝频谱应用DCT得到MFCC特征\n",
    "        y_db = librosa.power_to_db(y_mel)\n",
    "        y_mfcc = dct(y_db, axis=-2, type=2, norm=\"ortho\")[..., :n_mfcc, :]\n",
    "\n",
    "        # 对MFCC应用提升系数, 可以提高高频部分的分辨率\n",
    "        if lifter > 0:\n",
    "            n_lifter = np.sin(np.pi * np.arange(1, 1 + n_mfcc, dtype=y_mfcc.dtype) / lifter)\n",
    "            n_lifter = librosa.util.expand_to(n_lifter, ndim=y_db.ndim, axes=-2)\n",
    "            y_mfcc *= 1 + (lifter / 2) * n_lifter\n",
    "\n",
    "        # 保存数据 (转置是为了与后续的模型输入层维度匹配)\n",
    "        ds.append(y_mfcc.transpose())\n",
    "\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取音频模型均值, 标准差\n",
    "with open(FILES_PATH + \"dataset/data_mfcc.pkl\", \"rb\") as file:\n",
    "    _, mfcc_mean, mfcc_std = pickle.load(file)\n",
    "    del _\n",
    "\n",
    "# 读取词库\n",
    "with open(FILES_PATH + \"dataset/words_vec.pkl\", \"rb\") as file:\n",
    "    char2id, id2char = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "# 导入保存的模型\n",
    "bigru_model = load_model(FILES_PATH + 'models/bigru.h5')\n",
    "# wavenet_model = load_model(FILES_PATH + 'wavenet.h5')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 构建CTC解码模型\n",
    "CTC编码后的模型需要解码后才能输出对应标签的概率值  \n",
    "使用tf.keras.backend.ctc_decode进行解码  \n",
    "\n",
    "y_pred\t        包含预测的张量或 softmax 的输出 (samples, time_steps, num_categories)  \n",
    "input_length\t包含预测结果中每个批次序列长度的张量 (samples, 1)  \n",
    "greedy\t        如果true, 则执行更快的最佳路径搜索  \n",
    "beam_width\t    如果greedy是false, 波束搜索解码器将与此宽度的波束一起使用  \n",
    "top_paths\t    如果greedy是false, 将返回多少条最可能的路径  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ctc_decode_model(pred_audio, dict_list, model):\n",
    "    \"\"\"\n",
    "    使用模型对音频解码预测其内容\n",
    "    :param pred_audio:  需要预测的音频特征\n",
    "    :param dict_list:   转换标签所使用的词库\n",
    "    :param model:       预测使用的模型\n",
    "    :return:            (str, list) 返回预测的文本及其标签序号\n",
    "    \"\"\"\n",
    "    # 使用模型预测结果 (expand_dims用于增加维度匹配模型输入)\n",
    "    pred = model.predict(np.expand_dims(pred_audio, axis=0))\n",
    "    # 音频帧数\n",
    "    input_length = np.array((pred_audio.shape[1],))\n",
    "\n",
    "    # 解码\n",
    "    decode_res = ctc_decode(pred, input_length, greedy=True, beam_width=100, top_paths=1)\n",
    "    # 获取预测的序列数组, 筛选有效值 (> -1)\n",
    "    pred_index = get_value(decode_res[0][0])\n",
    "    pred_index = [item for item in pred_index[0] if item > -1]\n",
    "\n",
    "    # 使用词库将预测标号转换为文本\n",
    "    pred_text = \"\"\n",
    "    for index in pred_index:\n",
    "        pred_text += dict_list[index]\n",
    "\n",
    "    # 返回预测的文本及其标号\n",
    "    return pred_text, pred_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< Updated upstream
      "100%|██████████| 1/1 [00:00<00:00, 42.08it/s]"
=======
      "100%|██████████| 1/1 [00:01<00:00,  1.66s/it]"
>>>>>>> Stashed changes
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< Updated upstream
      "他们 能 作为 科研 的 梯队 顶 上来 我 也 可以 放心 去 干 我 所 喜爱 的 野外 考察 了\n"
=======
      "墙根 墙脚 则 往往 光溜溜 的 亮 是 孩子们 靠 在 墙上 玩耍 时 磨成 的\n"
>>>>>>> Stashed changes
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mfcc特征维数\n",
    "MFCC_VALUE = 32\n",
    "# FFT计算点数\n",
    "FFT = 512\n",
    "# 窗长\n",
    "WINLEN = 0.032\n",
    "\n",
    "# 随机读取读取一条语音\n",
    "index = random.randint(0, len(data_path) - 1)\n",
    "sound_mfcc = load_dataset_mfcc(\n",
    "    [data_path[index]],\n",
    "    n_mfcc=MFCC_VALUE,\n",
    "    is_emphasis=True,\n",
    "    n_fft=FFT,\n",
    "    win_length=WINLEN,\n",
    ")[0]\n",
    "# 标准化\n",
    "sound_mfcc = (sound_mfcc - mfcc_mean) / mfcc_std\n",
    "\n",
    "# 读取语音对应文本\n",
    "with open(label_path[index], \"r\") as file:\n",
    "    sound_text = file.readline().strip()\n",
    "\n",
    "print(sound_text)\n",
    "sound_mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< Updated upstream
      "1/1 [==============================] - 0s 92ms/step\n",
      "原文: 他们能作为科研的梯队顶上来我也可以放心去干我所喜爱的野外考察了\n",
      "识别: 他们能作为科研的梯队顶上来我也可以放心去干我所喜爱的野外考察了\n",
      "标号: [39, 60, 1081, 2216, 0, 4029, 1252, 1757, 5, 4, 95, 4030, 54, 425, 5, 69, 4031, 0, 4032, 1585, 1]\n"
=======
      "1/1 [==============================] - 3s 3s/step\n",
      "原文: 墙根墙脚则往往光溜溜的亮是孩子们靠在墙上玩耍时磨成的\n",
      "识别: 墙根墙脚则往往光溜溜的亮是孩子们靠时墙上玩耍时磨成的\n",
      "标号: [6300, 6301, 87, 226, 6302, 0, 6303, 7, 2438, 375, 43, 6304, 6305, 43, 2542, 0]\n"
>>>>>>> Stashed changes
     ]
    }
   ],
   "source": [
    "bigru_text, bigru_textid = ctc_decode_model(sound_mfcc, id2char, bigru_model)\n",
    "\n",
    "print(\"原文:\", sound_text.replace(\" \", \"\"))\n",
    "print(\"识别:\", bigru_text)\n",
    "print(\"标号:\", bigru_textid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
<<<<<<< Updated upstream
   "outputs": [],
=======
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 3s 3s/step\n",
      "原文: 墙根墙脚则往往光溜溜的亮是孩子们靠在墙上玩耍时磨成的\n",
      "识别: 且湖口县\n",
      "标号: [468, 2938]\n"
     ]
    }
   ],
>>>>>>> Stashed changes
   "source": [
    "# wavenet_text, wavenet_textid = ctc_decode_model(sound_mfcc, id2char, wavenet_model)\n",
    "\n",
    "# print(\"原文:\", sound_text.replace(\" \", \"\"))\n",
    "# print(\"识别:\", wavenet_text)\n",
    "# print(\"标号:\", wavenet_textid)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "7ad05525b964f9a3219eb93b0946337e1e9a632ab3f307ade25b62443cfe7aec"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
