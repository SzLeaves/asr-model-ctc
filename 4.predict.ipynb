{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 模型解码/预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import pickle\n",
    "import random\n",
    "from functools import reduce\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "import librosa\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from scipy.fftpack import dct\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "keras = tf.keras\n",
    "ctc_decode, get_value, load_model = (\n",
    "    keras.backend.ctc_decode,\n",
    "    keras.backend.get_value,\n",
    "    keras.models.load_model,\n",
    ")\n",
    "\n",
    "# 音频/语音标注文件路径\n",
    "DS_PATH = \"data/\"\n",
    "# 模型文件路径\n",
    "FILES_PATH = \"output/\"\n",
    "\n",
    "# 音频文件路径\n",
    "data_path = sorted([str(p) for p in pathlib.Path(DS_PATH).glob(\"*.wav\")])\n",
    "# 语音标注文件路径\n",
    "label_path = sorted([str(p) for p in pathlib.Path(DS_PATH).glob(\"*.trn\")])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. 加载模型与数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset_mfcc(\n",
    "    file_path,\n",
    "    sr=16000,\n",
    "    n_mfcc=13,\n",
    "    n_fft=512,\n",
    "    min_db=23,\n",
    "    emphasis=0.97,\n",
    "    hop_length=0.01,\n",
    "    win_length=0.025,\n",
    "    lifter=22,\n",
    "    is_emphasis=False,\n",
    "):\n",
    "    \"\"\"\n",
    "    加载并提取音频特征, 返回经过预处理的音频mfcc数组\n",
    "    :param file_path:    list 音频文件路径\n",
    "    :param sr:           int 音频采样率\n",
    "    :param n_mfcc:       int mfcc特征维度\n",
    "    :param n_fft:        int stft计算点数\n",
    "    :param min_db:       float 删除静音片段的最小分贝数\n",
    "    :param emphasis:     float 预加重系数\n",
    "    :param hop_length:   float 分帧间隔长度\n",
    "    :param win_length:   float 分窗长度\n",
    "    :param lifter:       int 对倒谱应用系数提升, 数值为正数\n",
    "    :param is_emphasis:  bool 是否进行预加重\n",
    "    :return:             np.ndarray 包含所有音频文件的mfcc特征二维数组 (frames, n_mfcc)\n",
    "    \"\"\"\n",
    "    ds = list()\n",
    "    for path in tqdm(file_path):\n",
    "        # 读取文件\n",
    "        y, sr = librosa.load(path=path, sr=sr)\n",
    "\n",
    "        # 去除音频中所有的空白静默部分\n",
    "        y_split = librosa.effects.split(y, top_db=min_db)\n",
    "        y_split = np.array(list(reduce(lambda x, y: np.concatenate((x, y)), [y[x[0] : x[1]] for x in y_split])))\n",
    "\n",
    "        # 预加重\n",
    "        if is_emphasis:\n",
    "            y_split = librosa.effects.preemphasis(y_split, coef=emphasis)\n",
    "\n",
    "        # 提取Mel频谱\n",
    "        y_mel = librosa.feature.melspectrogram(\n",
    "            y=y_split, sr=sr, n_fft=n_fft, hop_length=int(sr * hop_length), win_length=int(sr * win_length)\n",
    "        )\n",
    "\n",
    "        # 对分贝频谱应用DCT得到MFCC特征\n",
    "        y_db = librosa.power_to_db(y_mel)\n",
    "        y_mfcc = dct(y_db, axis=-2, type=2, norm=\"ortho\")[..., :n_mfcc, :]\n",
    "\n",
    "        # 对MFCC应用提升系数, 可以提高高频部分的分辨率\n",
    "        if lifter > 0:\n",
    "            n_lifter = np.sin(np.pi * np.arange(1, 1 + n_mfcc, dtype=y_mfcc.dtype) / lifter)\n",
    "            n_lifter = librosa.util.expand_to(n_lifter, ndim=y_db.ndim, axes=-2)\n",
    "            y_mfcc *= 1 + (lifter / 2) * n_lifter\n",
    "\n",
    "        # 保存数据 (转置是为了与后续的模型输入层维度匹配)\n",
    "        ds.append(y_mfcc.transpose())\n",
    "\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取音频模型均值, 标准差\n",
    "with open(FILES_PATH + \"dataset/data_mfcc.pkl\", \"rb\") as file:\n",
    "    _, mfcc_mean, mfcc_std = pickle.load(file)\n",
    "    del _\n",
    "\n",
    "# 读取词库\n",
    "with open(FILES_PATH + \"dataset/words_vec.pkl\", \"rb\") as file:\n",
    "    char2id, id2char = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "# 导入保存的模型\n",
    "bigru_model = load_model(FILES_PATH + 'models/test/conv/bigru-conv-x4.h5')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 构建CTC解码模型\n",
    "CTC编码后的模型需要解码后才能输出对应标签的概率值  \n",
    "使用贪婪法（Greedy）进行概率路径搜索，速度较快"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ctc_decode_model(pred_audio, dict_list, model):\n",
    "    \"\"\"\n",
    "    使用模型对音频解码预测其内容\n",
    "    :param pred_audio:  需要预测的音频特征\n",
    "    :param dict_list:   转换标签所使用的词库\n",
    "    :param model:       预测使用的模型\n",
    "    :return:            (str, list) 返回预测的文本及其标签序号\n",
    "    \"\"\"\n",
    "    # 使用模型预测结果 (expand_dims用于增加维度匹配模型输入)\n",
    "    pred = model.predict(np.expand_dims(pred_audio, axis=0))\n",
    "    # 音频帧数\n",
    "    input_length = np.array((pred_audio.shape[1],))\n",
    "\n",
    "    # 解码\n",
    "    decode_res = ctc_decode(pred, input_length, greedy=True)\n",
    "    # 获取预测的序列数组, 筛选有效值 (> -1)\n",
    "    pred_index = get_value(decode_res[0][0])\n",
    "    pred_index = [item for item in pred_index[0] if item > -1]\n",
    "\n",
    "    # 使用词库将预测标号转换为文本\n",
    "    pred_text = \"\"\n",
    "    for index in pred_index:\n",
    "        pred_text += dict_list[index]\n",
    "\n",
    "    # 返回预测的文本及其标号\n",
    "    return pred_text, pred_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 19.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "设 想要 海阔天空 观察 要 全面 细致 立论 要 有根有据 这 是 欧阳 自 远 的 治学 准则\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.40737426,  0.26993084,  0.5791348 , ...,  0.30544364,\n",
       "        -0.24460006, -0.02492859],\n",
       "       [-0.33968562, -0.0333352 ,  0.6054428 , ..., -0.45069125,\n",
       "        -0.68631834,  0.5700822 ],\n",
       "       [ 0.22862393, -0.74437404,  0.9437078 , ..., -0.14002994,\n",
       "         0.7798456 ,  1.176097  ],\n",
       "       ...,\n",
       "       [-1.1548744 ,  0.06848073,  0.5091384 , ...,  0.52224696,\n",
       "         0.8139538 ,  0.5535394 ],\n",
       "       [-1.1410512 , -0.03751895,  0.4478758 , ...,  0.73892367,\n",
       "         1.009853  ,  0.7052412 ],\n",
       "       [-1.1108539 , -0.17889705,  0.26301256, ...,  0.46345124,\n",
       "         0.4837918 ,  0.14051166]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mfcc特征维数\n",
    "MFCC_VALUE = 32\n",
    "# FFT计算点数\n",
    "FFT = 512\n",
    "# 窗长\n",
    "WINLEN = 0.032\n",
    "\n",
    "# 随机读取读取一条语音\n",
    "index = random.randint(0, len(data_path) - 1)\n",
    "sound_mfcc = load_dataset_mfcc(\n",
    "    [data_path[index]],\n",
    "    n_mfcc=MFCC_VALUE,\n",
    "    is_emphasis=True,\n",
    "    n_fft=FFT,\n",
    "    win_length=WINLEN,\n",
    ")[0]\n",
    "# 标准化\n",
    "sound_mfcc = (sound_mfcc - mfcc_mean) / mfcc_std\n",
    "\n",
    "# 读取语音对应文本\n",
    "with open(label_path[index], \"r\") as file:\n",
    "    sound_text = file.readline().strip()\n",
    "\n",
    "print(sound_text)\n",
    "sound_mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 85ms/step\n",
      "原文: 设想要海阔天空观察要全面细致立论要有根有据这是欧阳自远的治学准则\n",
      "识别: 设想要海阔天空观察要全面细致立论要有根有据这是欧阳自远的治学准则\n",
      "标号: [1524, 1701, 3620, 977, 14, 3621, 3622, 3623, 14, 3624, 28, 7, 649, 807, 384, 0, 3625, 3626]\n"
     ]
    }
   ],
   "source": [
    "bigru_text, bigru_textid = ctc_decode_model(sound_mfcc, id2char, bigru_model)\n",
    "\n",
    "print(\"原文:\", sound_text.replace(\" \", \"\"))\n",
    "print(\"识别:\", bigru_text)\n",
    "print(\"标号:\", bigru_textid)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "7ad05525b964f9a3219eb93b0946337e1e9a632ab3f307ade25b62443cfe7aec"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
