{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 音频 / 语音标注数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import pickle\n",
    "import random\n",
    "from functools import reduce\n",
    "from collections import Counter\n",
    "\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import ticker\n",
    "from scipy.fftpack import dct\n",
    "from tqdm import tqdm\n",
    "\n",
    "plt.rcParams[\"font.sans-serif\"] = [\"Microsoft YaHei\"]\n",
    "plt.rcParams[\"axes.unicode_minus\"] = False\n",
    "\n",
    "# 音频/语音标注文件路径\n",
    "DS_PATH = \"data/\"\n",
    "# 保存文件路径\n",
    "FILES_PATH = \"output/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. 音频数据处理\n",
    "读取音频文件 -> 去除静音部分 -> 提取MFCC特征 -> 数据标准化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 音频文件路径\n",
    "data_path = sorted([str(p) for p in pathlib.Path(DS_PATH).glob(\"*.wav\")])\n",
    "# 语音标注文件路径\n",
    "label_path = sorted([str(p) for p in pathlib.Path(DS_PATH).glob(\"*.trn\")])\n",
    "# 查看前5个数据与标注，排序是为了音频与标注文件按名称一一对应\n",
    "for x, y in zip(data_path[:5], label_path[:5]):\n",
    "    print(x, y, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从数据集中抽取一半的数量用于数据增强\n",
    "ex_index = random.sample(range(len(data_path)), len(data_path) // 2)\n",
    "ex_data_path = [data_path[i] for i in ex_index]\n",
    "ex_label_path = [label_path[i] for i in ex_index]\n",
    "\n",
    "# 查看前5个数据与标注\n",
    "for x, y in zip(ex_data_path[:5], ex_label_path[:5]):\n",
    "    print(x, y, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0.1 读取音频数据并提取MFCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spec_augment(melspec, num_mask=1, freq_masking=0.15, time_masking=0.20):\n",
    "    \"\"\"\n",
    "    对音频进行数据增强, 返回增强后的音频Mel频谱\n",
    "    :param melspec:       ndarray 需要处理的Mel频谱\n",
    "    :param num_mask:      int 掩码区域数量\n",
    "    :param freq_masking   float 频率掩码参数，表示要掩盖的连续频率区域的数量\n",
    "    :param time_masking:  float 时间掩码参数，表示要掩盖的连续时间区域的数量\n",
    "    :return               (n_mels, n_frames) 增强后的Mel频谱\n",
    "    \"\"\"\n",
    "\n",
    "    melspec = melspec.copy()\n",
    "    # 时间/频率屏蔽\n",
    "    for i in range(num_mask):\n",
    "        # 随机选择遮挡区域\n",
    "        freq_dim, time_dim = melspec.shape\n",
    "        freq_mask_num = int(freq_dim * freq_masking)\n",
    "        time_mask_num = int(time_dim * time_masking)\n",
    "\n",
    "        # 随机选择遮挡位置\n",
    "        freq_mask_pos = np.random.randint(0, freq_dim - freq_mask_num, 1)[0]\n",
    "        time_mask_pos = np.random.randint(0, time_dim - time_mask_num, 1)[0]\n",
    "\n",
    "        # 遮挡Mel频谱\n",
    "        melspec[freq_mask_pos : freq_mask_pos + freq_mask_num, :] = 0\n",
    "        melspec[:, time_mask_pos : time_mask_pos + time_mask_num] = 0\n",
    "\n",
    "    return melspec\n",
    "\n",
    "\n",
    "def load_dataset_mfcc(\n",
    "    file_path,\n",
    "    sr=16000,\n",
    "    n_mfcc=13,\n",
    "    n_fft=512,\n",
    "    n_mask=1,\n",
    "    min_db=23,\n",
    "    emphasis=0.97,\n",
    "    hop_length=0.01,\n",
    "    win_length=0.025,\n",
    "    lifter=22,\n",
    "    is_emphasis=False,\n",
    "    is_spec=False,\n",
    "):\n",
    "    \"\"\"\n",
    "    加载并提取音频特征, 返回经过预处理的音频mfcc数组\n",
    "    :param file_path:    list 音频文件路径\n",
    "    :param sr:           int 音频采样率\n",
    "    :param n_mfcc:       int mfcc特征维度\n",
    "    :param n_fft:        int stft计算点数\n",
    "    :param n_mask:       int 对Mel频谱的掩码数量 (is_spec=True时有效)\n",
    "    :param min_db:       float 删除静音片段的最小分贝数\n",
    "    :param emphasis:     float 预加重系数\n",
    "    :param hop_length:   float 分帧间隔长度\n",
    "    :param win_length:   float 分窗长度\n",
    "    :param lifter:       int 对倒谱应用系数提升, 数值为正数\n",
    "    :param is_emphasis:  bool 是否进行预加重\n",
    "    :param is_spec:      bool 是否进行额外的数据增强\n",
    "    :return:             np.ndarray 包含所有音频文件的mfcc特征二维数组 (frames, n_mfcc)\n",
    "    \"\"\"\n",
    "    ds = list()\n",
    "    for path in tqdm(file_path):\n",
    "        # 读取文件\n",
    "        y, sr = librosa.load(path=path, sr=sr)\n",
    "\n",
    "        # 去除音频中所有的空白静默部分\n",
    "        y_split = librosa.effects.split(y, top_db=min_db)\n",
    "        y_split = np.array(list(reduce(lambda x, y: np.concatenate((x, y)), [y[x[0] : x[1]] for x in y_split])))\n",
    "\n",
    "        # 预加重\n",
    "        if is_emphasis:\n",
    "            y_split = librosa.effects.preemphasis(y_split, coef=emphasis)\n",
    "\n",
    "        # 提取Mel频谱\n",
    "        y_mel = librosa.feature.melspectrogram(\n",
    "            y=y_split, sr=sr, n_fft=n_fft, hop_length=int(sr * hop_length), win_length=int(sr * win_length)\n",
    "        )\n",
    "\n",
    "        # SpecAugment 数据增强\n",
    "        if is_spec:\n",
    "            y_mel = spec_augment(y_mel, num_mask=n_mask)\n",
    "\n",
    "        # 对分贝频谱应用DCT得到MFCC特征\n",
    "        y_db = librosa.power_to_db(y_mel)\n",
    "        y_mfcc = dct(y_db, axis=-2, type=2, norm=\"ortho\")[..., :n_mfcc, :]\n",
    "\n",
    "        # 对MFCC应用提升系数, 可以提高高频部分的分辨率\n",
    "        if lifter > 0:\n",
    "            n_lifter = np.sin(np.pi * np.arange(1, 1 + n_mfcc, dtype=y_mfcc.dtype) / lifter)\n",
    "            n_lifter = librosa.util.expand_to(n_lifter, ndim=y_db.ndim, axes=-2)\n",
    "            y_mfcc *= 1 + (lifter / 2) * n_lifter\n",
    "\n",
    "        # 保存数据 (转置是为了与后续的模型输入层维度匹配)\n",
    "        ds.append(y_mfcc.transpose())\n",
    "\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mfcc特征维数\n",
    "MFCC_VALUE = 32\n",
    "# FFT计算点数\n",
    "FFT = 1024\n",
    "# 窗长\n",
    "WINLEN = 0.032"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取并处理数据\n",
    "train_ds = load_dataset_mfcc(\n",
    "    data_path, n_mfcc=MFCC_VALUE, n_fft=FFT, win_length=WINLEN, is_emphasis=True\n",
    ")\n",
    "ex_train_ds = load_dataset_mfcc(\n",
    "    ex_data_path, n_mfcc=MFCC_VALUE, n_fft=FFT, win_length=WINLEN, is_emphasis=True, is_spec=True\n",
    ")\n",
    "\n",
    "# 拼接数据增强结果\n",
    "train_ds.extend(ex_train_ds)\n",
    "print(len(train_ds), train_ds[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 0.2 数据标准化\n",
    "训练集和验证集的最大值、最小值的数值之间存在较大的差距。因此需要通过标准化处理，使特征具有相同的量纲"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 按每列的MFCC维数计算均值\n",
    "train_ds_std = np.vstack(train_ds)\n",
    "\n",
    "print(train_ds_std.shape)\n",
    "print(\"最大值:\", np.max(train_ds_std))\n",
    "print(\"最小值\", np.min(train_ds_std))\n",
    "print(\"均值:\", np.mean(train_ds_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算整体均值\n",
    "mfcc_mean = np.mean(train_ds_std, axis=0)\n",
    "# 计算整体标准差\n",
    "mfcc_std = np.std(train_ds_std, axis=0)\n",
    "del train_ds_std\n",
    "\n",
    "# 数据标准化: x数据值 - X数据均值 / S标准差\n",
    "train_ds = [(x - mfcc_mean) / (mfcc_std + 1e-14) for x in train_ds]\n",
    "\n",
    "# 查看某帧的标准化结果\n",
    "train_ds[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### EDA: 删除静音部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 随机读取原音频\n",
    "sound = random.choice(data_path)\n",
    "y, sr = librosa.load(path=sound, sr=16000)\n",
    "\n",
    "# 去除分贝小于指定部分的音频区间(空白区间)\n",
    "y_split = librosa.effects.split(y, top_db=23)\n",
    "y_split = np.array(list(reduce(lambda x, y: np.concatenate((x, y)), [y[x[0] : x[1]] for x in y_split])))\n",
    "\n",
    "# 画图查看结果\n",
    "plt.figure(figsize=(8, 5), dpi=100)\n",
    "plt.subplots_adjust(hspace=0.6)\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.title(sound.replace(DS_PATH, \"\") + \" 原音频\")\n",
    "librosa.display.waveshow(y)\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.title(sound.replace(DS_PATH, \"\") + \" 删除静音的音频\")\n",
    "librosa.display.waveshow(y_split)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EDA: 数据增强"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提取Mel频谱\n",
    "mel = librosa.feature.melspectrogram(y=y, sr=sr)\n",
    "# 数据增强\n",
    "res = spec_augment(mel, num_mask=1)\n",
    "\n",
    "# 画图查看结果\n",
    "plt.figure(figsize=(13, 4), dpi=100)\n",
    "plt.subplots_adjust(wspace=0.2)\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "librosa.display.specshow(\n",
    "    librosa.power_to_db(mel, ref=np.max), y_axis=\"mel\", fmax=8000, x_axis=\"time\", cmap=\"Greys\"\n",
    ")\n",
    "plt.colorbar(format=\"%+2.0f dB\")\n",
    "plt.title(\"SpecAugment 使用前\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "librosa.display.specshow(\n",
    "    librosa.power_to_db(res, ref=np.max), y_axis=\"mel\", fmax=8000, x_axis=\"time\", cmap=\"Greys\"\n",
    ")\n",
    "plt.colorbar(format=\"%+2.0f dB\")\n",
    "plt.title(\"SpecAugment 使用后\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### EDA: 查看不同特征维度下的MFCC频谱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mfcc_a = 13\n",
    "mfcc_b = 32\n",
    "sound_mfcc_a = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=mfcc_a, n_fft=FFT)\n",
    "sound_mfcc_b = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=mfcc_b, n_fft=FFT)\n",
    "\n",
    "plt.figure(figsize=(13, 4), dpi=100)\n",
    "plt.subplots_adjust(wspace=0.2)\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "librosa.display.specshow(data=sound_mfcc_a, sr=sr, x_axis=\"time\", y_axis=\"mel\")\n",
    "plt.title(sound[5:] + \" MFCC (n_mfcc=%d)\" % mfcc_a)\n",
    "plt.colorbar(format=\"%+2.0f\")\n",
    "plt.subplot(1, 2, 2)\n",
    "librosa.display.specshow(data=sound_mfcc_b, sr=sr, x_axis=\"time\", y_axis=\"mel\")\n",
    "plt.title(sound[5:] + \" MFCC (n_mfcc=%d)\" % mfcc_b)\n",
    "plt.colorbar(format=\"%+2.0f\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### EDA: 查看原音频帧长的分布情况"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 计算所有音频的帧数\n",
    "dim_list = [x.shape[0] for x in train_ds]\n",
    "\n",
    "# 计数柱状图\n",
    "plt.figure(figsize=(10, 3), dpi=115)\n",
    "sns.countplot(x=dim_list, width=0.8)\n",
    "# 调整x坐标间隔\n",
    "plt.gca().xaxis.set_major_locator(ticker.MultipleLocator(25))\n",
    "plt.title(\"MFCC frame\")\n",
    "plt.xlabel(\"frames\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 语音标注数据处理\n",
    "读取标注文件内容 -> 选择字标注作为标签 ->  生成词库 / 标签向量化 -> 映射标签到对应词库文本"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 读取标注文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = list()\n",
    "ex_labels = list()\n",
    "\n",
    "# 原数据集\n",
    "for path in tqdm(label_path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as file:\n",
    "        # 读取第一行的字标注\n",
    "        labels.append(file.readline().strip())\n",
    "\n",
    "# 增强数据集\n",
    "for path in tqdm(ex_label_path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as file:\n",
    "        ex_labels.append(file.readline().strip())\n",
    "\n",
    "labels[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 使用Counter计算词频，按照词频降序排序后按顺序取标签序号"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_all = sorted(Counter(\" \".join(labels).split()).items(), key=lambda x: x[1], reverse=True)\n",
    "# 取出排序后的词作为词库\n",
    "words_list = [x[0] for x in text_all]\n",
    "del text_all\n",
    "# 对词库标签向量化\n",
    "char2id = {word: index for index, word in enumerate(words_list)}\n",
    "id2char = {index: word for index, word in enumerate(words_list)}\n",
    "\n",
    "# 查看向量化结果\n",
    "print(list(char2id.items())[:10])\n",
    "print(list(id2char.items())[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 映射序号到对应的词库文本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_split = [x.split() for x in labels]\n",
    "# 映射标签\n",
    "train_label = list()\n",
    "for word_list in labels_split:\n",
    "    train_label.append([char2id[x] for x in word_list])\n",
    "\n",
    "# 查看前3个标签的映射结果\n",
    "for label, ids in zip(labels_split[:3], train_label[:3]):\n",
    "    print(\"文本:\", \" \".join(label))\n",
    "    print(\"标签:\", \" \".join([str(x) for x in ids]), end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 2. 保存音频/标签数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 保存音频MFCC特征, 均值, 标准差\n",
    "with open(FILES_PATH + \"dataset/data_mfcc.pkl\", \"wb\") as file:\n",
    "    pickle.dump((train_ds, mfcc_mean, mfcc_std), file)\n",
    "\n",
    "# 保存音频标注\n",
    "with open(FILES_PATH + \"dataset/labels.pkl\", \"wb\") as file:\n",
    "    labels.extend(ex_labels)\n",
    "    pickle.dump(labels, file)\n",
    "    print(len(labels))\n",
    "\n",
    "# 保存词库\n",
    "with open(FILES_PATH + \"dataset/words_vec.pkl\", \"wb\") as file:\n",
    "    pickle.dump((char2id, id2char), file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "7ad05525b964f9a3219eb93b0946337e1e9a632ab3f307ade25b62443cfe7aec"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
